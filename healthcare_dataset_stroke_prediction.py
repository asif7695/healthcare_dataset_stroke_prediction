# -*- coding: utf-8 -*-
"""healthcare-dataset-stroke-prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ndkw42Vy_ES__grhs8jMvvNx5Wdmx2H0
"""

import numpy as np
import pandas as pd


from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer

"""#Data Loading"""

df = pd.read_csv('D:\healthcare_dataset_stroke_prediction\healthcare-dataset-stroke-data.csv') #https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset

df.sample(5)

df.shape

df.info()

df['bmi'].fillna(df['bmi'].median(), inplace=True)

df.describe().T

df.drop('id', axis=1, inplace=True)

#avg_glucose_level

Q1_glucose = df['avg_glucose_level'].quantile(0.25)
Q3_glucose = df['avg_glucose_level'].quantile(0.75)
IQR_glucose = Q3_glucose - Q1_glucose

lower_glucose = Q1_glucose - 1.5 * IQR_glucose
upper_glucose = Q3_glucose + 1.5 * IQR_glucose

df['avg_glucose_level'] = df['avg_glucose_level'].clip(
    lower=lower_glucose,
    upper=upper_glucose
)

# bmi outlier capping

Q1_bmi = df['bmi'].quantile(0.25)
Q3_bmi = df['bmi'].quantile(0.75)
IQR_bmi = Q3_bmi - Q1_bmi

lower_bmi = Q1_bmi - 1.5 * IQR_bmi
upper_bmi = Q3_bmi + 1.5 * IQR_bmi

df['bmi'] = df['bmi'].clip(
    lower=lower_bmi,
    upper=upper_bmi
)



df.describe().T

def age_group(age):
    if age < 20:
        return 'young'
    elif age < 40:
        return 'adult'
    elif age < 60:
        return 'middle_aged'
    else:
        return 'senior'

df['age_group'] = df['age'].apply(age_group)

df.sample(5)

"""# preprocesor pipeline"""

X = df.drop(columns=['stroke'])
Y = df['stroke']

df.drop(columns=['stroke'],axis=1,inplace=True)

df.sample(5)

num_cols = df.select_dtypes(include=['int64', 'float64']).columns
cat_cols = df.select_dtypes(include=['object']).columns
print(num_cols)
print(cat_cols)

num_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy='median')),
    ('scaler',StandardScaler())
])

cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(transformers=[
    ('num',num_transformer,num_cols),
    ('cat',cat_transformer,cat_cols)
])

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""#Primary Model Selection"""

#model selection
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix

lr = LogisticRegression()
rf = RandomForestClassifier()
gb = GradientBoostingClassifier()

model_to_run = {
    'Logistic Regression': lr,
    'Random Forest': rf,
    'Gradient Boosting': gb
}

"""#Model Training"""

res = []

for name,model in model_to_run.items():
  pipe = Pipeline(steps=[
      ('preprocessor',preprocessor),
      ('model',model)
  ])

  #fit
  pipe.fit(x_train,y_train)

  #predict
  y_pred = pipe.predict(x_test)

  #evaluation
  precision = precision_score(y_test,y_pred)
  recall = recall_score(y_test,y_pred)
  f1 = f1_score(y_test,y_pred)
  roc_auc = roc_auc_score(y_test,y_pred)
  acc = accuracy_score(y_test,y_pred)

  res.append({
      'model':name,
      'precision_score':precision,
      'recall_score':recall,
      'f1_score':f1,
      'roc_auc_score':roc_auc,
      'accuracy_score':acc
  })
evaluation = pd.DataFrame(res).sort_values(by='recall_score',ascending=False)
evaluation

"""# Cross Validation"""

from sklearn.model_selection import cross_val_score

"""for gradiant boosting"""

gb_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', GradientBoostingClassifier(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=3,
        random_state=42
    ))
])

cv_scores = cross_val_score(
    gb_pipe,
    x_train,
    y_train,
    cv=5,
    scoring='recall'
)

print("Recall scores:", cv_scores)
print("Mean recall:", cv_scores.mean())
print("Std recall:", cv_scores.std())

"""for logistic regression

"""

lr_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LogisticRegression(
        max_iter=1000,
        class_weight='balanced',
        random_state=42
    ))
])

cv_scores = cross_val_score(
    lr_pipe,
    x_train,
    y_train,
    cv=5,
    scoring='recall'
)

print("Recall scores:", cv_scores)
print("Mean recall:", cv_scores.mean())
print("Std recall:", cv_scores.std())

"""for random forest"""

rf_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestClassifier(
        n_estimators=300,
        class_weight='balanced',
        random_state=42
    ))
])

cv_scores = cross_val_score(
    rf_pipe,
    x_train,
    y_train,
    cv=5,
    scoring='recall'
)

print("Recall scores:", cv_scores)
print("Mean recall:", cv_scores.mean())
print("Std recall:", cv_scores.std())

"""# Hyperparameter Tuning"""

from sklearn.model_selection import GridSearchCV

logreg_pipe = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LogisticRegression(
        class_weight='balanced',   # CRITICAL for stroke data
        max_iter=1000,
        random_state=42
    ))
])

param_grid = {
    'model__C': [0.01, 0.1, 1, 10],
    'model__penalty': ['l2'],
    'model__solver': ['lbfgs']
}

from sklearn.model_selection import GridSearchCV

grid_search = GridSearchCV(
    estimator=logreg_pipe,
    param_grid=param_grid,
    scoring='recall',   # IMPORTANT
    cv=5,
    verbose=2,
    n_jobs=-1
)

grid_search.fit(x_train, y_train)

print("Best CV Recall:", grid_search.best_score_)
print("Best Parameters:", grid_search.best_params_)

"""# Final Model

The best model here is the tuned logistic regression. As before tuning the the gradiant boosting was better but was not good enough. But after tuning the logistic regression has better recall which is way better then before.
"""

best_model_obj = grid_search.best_estimator_
print(best_model_obj)

"""#Model Performance Evaluation"""

print("precision:", precision_score(y_test,y_pred))
print("recall:", recall_score(y_test,y_pred))
print("f1_score:", f1_score(y_test,y_pred))
print("roc_auc:", roc_auc_score(y_test,y_pred))

print("confusion matrix:\n", confusion_matrix(y_test,y_pred))

"""#Svaing the file"""

import pickle
filename = 'finalized_stroke_pred_model_with_tuned_lr.pkl'
pickle.dump(best_model_obj, open(filename, 'wb'))